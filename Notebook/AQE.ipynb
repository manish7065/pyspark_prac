{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/06/24 23:44:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"AQE Example\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.skewJoin.enabled\", \"true\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:===========>                                            (13 + 51) / 64]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+-----+\n",
      "| id| name| id| name|\n",
      "+---+-----+---+-----+\n",
      "|  1|Alice|  1|Alice|\n",
      "|  2|  Bob|  2|  Bob|\n",
      "|  3|Cathy|  3|Cathy|\n",
      "|  4|David|  4|David|\n",
      "+---+-----+---+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Creating a Spark DataFrame\n",
    "data = [(1, \"Alice\"), (2, \"Bob\"), (3, \"Cathy\"), (4, \"David\")]\n",
    "df = spark.createDataFrame(data, [\"id\", \"name\"])\n",
    "\n",
    "# Example query that involves a join\n",
    "df1 = df.alias(\"df1\")\n",
    "df2 = df.alias(\"df2\")\n",
    "\n",
    "# Join operation\n",
    "result = df1.join(df2, df1.id == df2.id)\n",
    "\n",
    "# Show the result\n",
    "result.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.31.1\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "print(sqlite3.sqlite_version)  # Check SQLite version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'Alice', 30)]\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Connect to a database (or create it if it doesn't exist)\n",
    "conn = sqlite3.connect('example.db')\n",
    "\n",
    "# Create a cursor object\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create a table\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS users\n",
    "                  (id INTEGER PRIMARY KEY, name TEXT, age INTEGER)''')\n",
    "\n",
    "# Insert a row of data\n",
    "cursor.execute(\"INSERT INTO users (name, age) VALUES ('Alice', 30)\")\n",
    "\n",
    "# Save (commit) the changes\n",
    "conn.commit()\n",
    "\n",
    "# Query the database\n",
    "cursor.execute(\"SELECT * FROM users\")\n",
    "print(cursor.fetchall())  # Fetch all results from the executed query\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/28 19:33:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+\n",
      "| id| name|age|\n",
      "+---+-----+---+\n",
      "|  1|Alice| 30|\n",
      "+---+-----+---+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SQLite JDBC\") \\\n",
    "    .config(\"spark.jars\", \"/config/workspace/sqlite-jdbc-3.46.0.0.jar\").getOrCreate()\n",
    "\n",
    "# SQLite database path\n",
    "db_path = \"example.db\"\n",
    "\n",
    "# JDBC URL for SQLite\n",
    "jdbc_url = f\"jdbc:sqlite:{db_path}\"\n",
    "\n",
    "# Reading data from SQLite table\n",
    "df = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", jdbc_url) \\\n",
    "    .option(\"dbtable\", \"users\") \\\n",
    "    .option(\"driver\", \"org.sqlite.JDBC\") \\\n",
    "    .load()\n",
    "\n",
    "# Show the data\n",
    "df.show()\n",
    "\n",
    "# Stop the SparkSession\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
