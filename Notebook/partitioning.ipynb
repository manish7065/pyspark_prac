{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partitioning practice to see the impact on execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/02 08:10:34 WARN Utils: Your hostname, manu-pc resolves to a loopback address: 127.0.1.1; using 192.168.34.41 instead (on interface wlp58s0)\n",
      "24/09/02 08:10:34 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/02 08:10:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"partitioning_session\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+--------+------------+---------+----------+------+--------------+----------+-------------+\n",
      "|employee_id|FIRST_NAME|LAST_NAME|   EMAIL|PHONE_NUMBER|HIRE_DATE|    JOB_ID|SALARY|COMMISSION_PCT|MANAGER_ID|DEPARTMENT_ID|\n",
      "+-----------+----------+---------+--------+------------+---------+----------+------+--------------+----------+-------------+\n",
      "|        198|    Donald| OConnell|DOCONNEL|650.507.9833|21-JUN-07|  SH_CLERK|  2600|          NULL|       124|           50|\n",
      "|        199|   Douglas|    Grant|  DGRANT|650.507.9844|13-JAN-08|  SH_CLERK|  2600|          NULL|       124|           50|\n",
      "|        200|  Jennifer|   Whalen| JWHALEN|515.123.4444|17-SEP-03|   AD_ASST|  4400|          NULL|       101|           10|\n",
      "|        201|   Michael|Hartstein|MHARTSTE|515.123.5555|17-FEB-04|    MK_MAN| 13000|          NULL|       100|           20|\n",
      "|        202|       Pat|      Fay|    PFAY|603.123.6666|17-AUG-05|    MK_REP|  6000|          NULL|       201|           20|\n",
      "|        203|     Susan|   Mavris| SMAVRIS|515.123.7777|07-JUN-02|    HR_REP|  6500|          NULL|       101|           40|\n",
      "|        204|   Hermann|     Baer|   HBAER|515.123.8888|07-JUN-02|    PR_REP| 10000|          NULL|       101|           70|\n",
      "|        205|   Shelley|  Higgins|SHIGGINS|515.123.8080|07-JUN-02|    AC_MGR| 12008|          NULL|       101|          110|\n",
      "|        206|   William|    Gietz|  WGIETZ|515.123.8181|07-JUN-02|AC_ACCOUNT|  8300|          NULL|       205|          110|\n",
      "|        100|    Steven|     King|   SKING|515.123.4567|17-JUN-03|   AD_PRES| 24000|          NULL|      NULL|           90|\n",
      "|        101|     Neena|  Kochhar|NKOCHHAR|515.123.4568|21-SEP-05|     AD_VP| 17000|          NULL|       100|           90|\n",
      "|        102|       Lex|  De Haan| LDEHAAN|515.123.4569|13-JAN-01|     AD_VP| 17000|          NULL|       100|           90|\n",
      "|        103| Alexander|   Hunold| AHUNOLD|590.423.4567|03-JAN-06|   IT_PROG|  9000|          NULL|       102|           60|\n",
      "|        104|     Bruce|    Ernst|  BERNST|590.423.4568|21-MAY-07|   IT_PROG|  6000|          NULL|       103|           60|\n",
      "|        105|     David|   Austin| DAUSTIN|590.423.4569|25-JUN-05|   IT_PROG|  4800|          NULL|       103|           60|\n",
      "|        106|     Valli|Pataballa|VPATABAL|590.423.4560|05-FEB-06|   IT_PROG|  4800|          NULL|       103|           60|\n",
      "|        107|     Diana|  Lorentz|DLORENTZ|590.423.5567|07-FEB-07|   IT_PROG|  4200|          NULL|       103|           60|\n",
      "|        108|     Nancy|Greenberg|NGREENBE|515.124.4569|17-AUG-02|    FI_MGR| 12008|          NULL|       101|          100|\n",
      "|        109|    Daniel|   Faviet| DFAVIET|515.124.4169|16-AUG-02|FI_ACCOUNT|  9000|          NULL|       108|          100|\n",
      "|        110|      John|     Chen|   JCHEN|515.124.4269|28-SEP-05|FI_ACCOUNT|  8200|          NULL|       108|          100|\n",
      "+-----------+----------+---------+--------+------------+---------+----------+------+--------------+----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_file_path = r\"../data/employees.csv\"\n",
    "\n",
    "df = spark.read.csv(data_file_path,inferSchema = True, header = True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## aggregation without partiotioning execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1725245591.3734844\n",
      "+-------------+-----------+\n",
      "|DEPARTMENT_ID|sum(SALARY)|\n",
      "+-------------+-----------+\n",
      "|           20|      19000|\n",
      "|           40|       6500|\n",
      "|          100|      51608|\n",
      "|           10|       4400|\n",
      "|           50|      85600|\n",
      "|           70|      10000|\n",
      "|           90|      58000|\n",
      "|           60|      28800|\n",
      "|          110|      20308|\n",
      "|           30|      24900|\n",
      "+-------------+-----------+\n",
      "\n",
      "1725245592.3519967\n",
      "exec_time:  0.9785122871398926\n"
     ]
    }
   ],
   "source": [
    "from time import sleep, time\n",
    "from pyspark.sql.functions import sum,col\n",
    "\n",
    "start_time = time()\n",
    "print(start_time)\n",
    "\n",
    "df.groupBy('DEPARTMENT_ID').agg(sum(col('SALARY'))).show()\n",
    "\n",
    "end_time = time()\n",
    "\n",
    "print(end_time)\n",
    "print(\"exec_time: \", end_time-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## aggregation with partition execution time \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1725246162.8037558\n",
      "+-------------+-----------+------------------+\n",
      "|DEPARTMENT_ID|sum(SALARY)|       avg(SALARY)|\n",
      "+-------------+-----------+------------------+\n",
      "|           20|      19000|            9500.0|\n",
      "|           40|       6500|            6500.0|\n",
      "|          100|      51608| 8601.333333333334|\n",
      "|           10|       4400|            4400.0|\n",
      "|           50|      85600|3721.7391304347825|\n",
      "|           70|      10000|           10000.0|\n",
      "|           90|      58000|19333.333333333332|\n",
      "|           60|      28800|            5760.0|\n",
      "|          110|      20308|           10154.0|\n",
      "|           30|      24900|            4150.0|\n",
      "+-------------+-----------+------------------+\n",
      "\n",
      "1725246163.0189307\n",
      "exec_time:  0.21517491340637207\n"
     ]
    }
   ],
   "source": [
    "from time import sleep, time\n",
    "from pyspark.sql.functions import sum,col\n",
    "\n",
    "df = df.repartition(\"DEPARTMENT_ID\")\n",
    "\n",
    "start_time = time()\n",
    "print(start_time)\n",
    "\n",
    "# df.groupBy('DEPARTMENT_ID').agg(sum(col('SALARY'))).show()\n",
    "df.groupBy(\"DEPARTMENT_ID\").agg(sum('SALARY'),avg('SALARY')).show() # WORKING\n",
    "\n",
    "\n",
    "end_time = time()\n",
    "\n",
    "print(end_time)\n",
    "print(\"exec_time: \", end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+------------------+\n",
      "|DEPARTMENT_ID|sum(SALARY)|       avg(SALARY)|\n",
      "+-------------+-----------+------------------+\n",
      "|           20|      19000|            9500.0|\n",
      "|           40|       6500|            6500.0|\n",
      "|          100|      51608| 8601.333333333334|\n",
      "|           10|       4400|            4400.0|\n",
      "|           50|      85600|3721.7391304347825|\n",
      "|           70|      10000|           10000.0|\n",
      "|           90|      58000|19333.333333333332|\n",
      "|           60|      28800|            5760.0|\n",
      "|          110|      20308|           10154.0|\n",
      "|           30|      24900|            4150.0|\n",
      "+-------------+-----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## aggregation trial\n",
    "from pyspark.sql.functions import avg\n",
    "\n",
    "\n",
    "# df.groupBy(\"DEPARTMENT_ID\").sum('SALARY').show() # working\n",
    "# df.groupBy(\"DEPARTMENT_ID\").agg({'SALARY':'sum'}).show() #  WORKING\n",
    "# df.groupBy(\"DEPARTMENT_ID\").agg({'SALARY':'sum'}).show() #  WORKING\n",
    "df.groupBy(\"DEPARTMENT_ID\").agg(sum('SALARY'),avg('SALARY')).show() # WORKING\n",
    "\n",
    "#\n",
    "\n",
    "# df.groupBy(\"DEPARTMENT_ID\").sum('SALARY').avg('SALARY').show() # NOT WORKING\n",
    "# df.groupBy(\"DEPARTMENT_ID\").agg('SALARY',sum('SALARY')).show() # NOT WORKING\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## join without partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a large DataFrame of transactions\n",
    "transactions_data = [(1, 100, '2023-01-01'),\n",
    "                     (2, 150, '2023-01-02'),\n",
    "                     (1, 200, '2023-01-03'),\n",
    "                     (3, 250, '2023-01-04'),\n",
    "                     (2, 300, '2023-01-05'),\n",
    "                     (4, 350, '2023-01-06'),\n",
    "                     (5, 400, '2023-01-07'),\n",
    "                     (3, 450, '2023-01-08'),\n",
    "                     (6, 500, '2023-01-09'),\n",
    "                     (7, 550, '2023-01-10')]\n",
    "\n",
    "transactions_columns = [\"user_id\", \"amount\", \"transaction_date\"]\n",
    "transactions_df = spark.createDataFrame(transactions_data, transactions_columns)\n",
    "\n",
    "# Create a small DataFrame of user information\n",
    "users_data = [(1, 'Alice'),\n",
    "              (2, 'Bob'),\n",
    "              (3, 'Charlie'),\n",
    "              (4, 'David'),\n",
    "              (5, 'Eve')]\n",
    "\n",
    "users_columns = [\"user_id\", \"name\"]\n",
    "users_df = spark.createDataFrame(users_data, users_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1725246803.070835\n",
      "+-------+-------+------+----------------+\n",
      "|user_id|   name|amount|transaction_date|\n",
      "+-------+-------+------+----------------+\n",
      "|      1|  Alice|   100|      2023-01-01|\n",
      "|      1|  Alice|   200|      2023-01-03|\n",
      "|      2|    Bob|   150|      2023-01-02|\n",
      "|      2|    Bob|   300|      2023-01-05|\n",
      "|      3|Charlie|   250|      2023-01-04|\n",
      "|      3|Charlie|   450|      2023-01-08|\n",
      "|      4|  David|   350|      2023-01-06|\n",
      "|      5|    Eve|   400|      2023-01-07|\n",
      "+-------+-------+------+----------------+\n",
      "\n",
      "1725246803.9494195\n",
      "exec_time:  0.8785843849182129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from time import sleep, time\n",
    "from pyspark.sql.functions import sum,col\n",
    "\n",
    "start_time = time()\n",
    "print(start_time)\n",
    "\n",
    "users_df.join(transactions_df, 'user_id').show()\n",
    "\n",
    "end_time = time()\n",
    "\n",
    "print(end_time)\n",
    "print(\"exec_time: \", end_time-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## join with partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1725246927.7953131\n",
      "+-------+-------+------+----------------+\n",
      "|user_id|   name|amount|transaction_date|\n",
      "+-------+-------+------+----------------+\n",
      "|      1|  Alice|   100|      2023-01-01|\n",
      "|      1|  Alice|   200|      2023-01-03|\n",
      "|      2|    Bob|   150|      2023-01-02|\n",
      "|      2|    Bob|   300|      2023-01-05|\n",
      "|      3|Charlie|   250|      2023-01-04|\n",
      "|      3|Charlie|   450|      2023-01-08|\n",
      "|      4|  David|   350|      2023-01-06|\n",
      "|      5|    Eve|   400|      2023-01-07|\n",
      "+-------+-------+------+----------------+\n",
      "\n",
      "1725246928.5160182\n",
      "exec_time:  0.7207050323486328\n"
     ]
    }
   ],
   "source": [
    "from time import sleep, time\n",
    "from pyspark.sql.functions import sum,col\n",
    "\n",
    "users_df = users_df.repartition(\"user_id\")\n",
    "transactions_df = transactions_df.repartition(\"user_id\")\n",
    "\n",
    "\n",
    "start_time = time()\n",
    "print(start_time)\n",
    "\n",
    "users_df.join(transactions_df, 'user_id').show()\n",
    "\n",
    "\n",
    "\n",
    "end_time = time()\n",
    "\n",
    "print(end_time)\n",
    "print(\"exec_time: \", end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying on Big data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_file_path = r\"/media/manu/sec_storage/data_set/employee_data/employee_data.csv\"\n",
    "recruitment_file_path = r\"/media/manu/sec_storage/data_set/employee_data/recruitment_data.csv\"\n",
    "\n",
    "employee_df = spark.read.csv(employee_file_path, inferSchema = True, header=True)\n",
    "recruitment_df = spark.read.csv(recruitment_file_path, inferSchema = True, header=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employee_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recruitment_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/02 09:42:55 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+--------+---------+---------+--------------------+-----------------+--------------------+------------+--------------+------------+-------+--------------------------+---------------+----------------------+-----------------+--------------------+----------+-----+----------------------+----------+------------+--------+-----------+-----------------+-----------------------+\n",
      "|EmpID|  FirstName|LastName|StartDate| ExitDate|               Title|       Supervisor|             ADEmail|BusinessUnit|EmployeeStatus|EmployeeType|PayZone|EmployeeClassificationType|TerminationType|TerminationDescription|   DepartmentType|            Division|       DOB|State|JobFunctionDescription|GenderCode|LocationCode|RaceDesc|MaritalDesc|Performance Score|Current Employee Rating|\n",
      "+-----+-----------+--------+---------+---------+--------------------+-----------------+--------------------+------------+--------------+------------+-------+--------------------------+---------------+----------------------+-----------------+--------------------+----------+-----+----------------------+----------+------------+--------+-----------+-----------------+-----------------------+\n",
      "| 3427|      Uriah| Bridges|20-Sep-19|     NULL|Production Techni...|     Peter Oneill|uriah.bridges@bil...|        CCDR|        Active|    Contract| Zone C|                 Temporary|            Unk|                  NULL|Production       |Finance & Accounting|07-10-1969|   MA|            Accounting|    Female|       34904|   White|    Widowed|      Fully Meets|                      4|\n",
      "| 3428|      Paula|   Small|11-Feb-23|     NULL|Production Techni...|  Renee Mccormick|paula.small@bilea...|          EW|        Active|    Contract| Zone A|                 Part-Time|            Unk|                  NULL|Production       |              Aerial|30-08-1965|   MA|                 Labor|      Male|        6593|Hispanic|    Widowed|      Fully Meets|                      3|\n",
      "| 3429|     Edward|    Buck|10-Dec-18|     NULL|  Area Sales Manager|   Crystal Walker|edward.buck@bilea...|          PL|        Active|   Full-Time| Zone B|                 Part-Time|            Unk|                  NULL|            Sales|       General - Sga|06-10-1991|   MA|             Assistant|      Male|        2330|Hispanic|    Widowed|      Fully Meets|                      4|\n",
      "| 3430|    Michael| Riordan|21-Jun-21|     NULL|  Area Sales Manager|   Rebekah Wright|michael.riordan@b...|        CCDR|        Active|    Contract| Zone A|                 Full-Time|            Unk|                  NULL|            Sales|Finance & Accounting|04-04-1998|   ND|                 Clerk|      Male|       58782|   Other|     Single|      Fully Meets|                      2|\n",
      "| 3431|    Jasmine|   Onque|29-Jun-19|     NULL|  Area Sales Manager|        Jason Kim|jasmine.onque@bil...|         TNS|        Active|    Contract| Zone A|                 Temporary|            Unk|                  NULL|            Sales|       General - Con|29-08-1969|   FL|               Laborer|    Female|       33174|   Other|    Married|      Fully Meets|                      3|\n",
      "| 3432|      Maruk|  Fraval|17-Jan-20|     NULL|  Area Sales Manager|     Sheri Campos|maruk.fraval@bile...|         BPC|        Active|    Contract| Zone B|                 Full-Time|            Unk|                  NULL|            Sales|    Field Operations|03-04-1949|   CT|                Driver|      Male|        6050|   Black|    Married|      Fully Meets|                      3|\n",
      "| 3433|      Latia|   Costa|06-Apr-22|03-Jul-23|  Area Sales Manager|      Jacob Braun|latia.costa@bilea...|         WBL|        Active|   Full-Time| Zone B|                 Temporary|    Involuntary|  Me see picture na...|            Sales|       General - Eng|01-07-1942|   CA|            Technician|    Female|       90007|Hispanic|   Divorced|          Exceeds|                      4|\n",
      "| 3434|   Sharlene|   Terry|06-Nov-20|29-Jan-23|  Area Sales Manager|    Tracy Marquez|sharlene.terry@bi...|        CCDR|        Active|    Contract| Zone C|                 Full-Time|    Involuntary|  Blue community ty...|            Sales|           Engineers|07-03-1957|   OR|              Engineer|    Female|       97756|   White|   Divorced|      Fully Meets|                      2|\n",
      "| 3435|        Jac|McKinzie|18-Aug-18|     NULL|  Area Sales Manager|    Sharon Becker|jac.mckinzie@bile...|         NEL|        Active|    Contract| Zone B|                 Part-Time|            Unk|                  NULL|            Sales|           Executive|15-05-1974|   TX|   Executive Assistant|      Male|       78789|   Black|    Widowed|          Exceeds|                      3|\n",
      "| 3436|     Joseph| Martins|21-Jan-22|29-Jun-23|  Area Sales Manager|   George Jenkins|joseph.martins@bi...|         BPC|        Active|   Part-Time| Zone B|                 Temporary|    Resignation|  Summer personal bag.|            Sales|           Engineers|11-11-1949|   TX|              Engineer|      Male|       78207|   Asian|    Widowed|      Fully Meets|                      5|\n",
      "| 3437|     Myriam|  Givens|04-Aug-23|     NULL|  Area Sales Manager|       Troy White|myriam.givens@bil...|         SVG|        Active|    Contract| Zone B|                 Temporary|            Unk|                  NULL|            Sales|    Field Operations|26-01-1964|   IN|            Technician|    Female|       46204|   Other|     Single|      Fully Meets|                      5|\n",
      "| 3438|     Dheepa|  Nguyen|10-Aug-18|04-Nov-19|  Area Sales Manager|     Brian Miller|dheepa.nguyen@bil...|         MSC|        Active|   Full-Time| Zone C|                 Temporary|     Retirement|  Alone once than. ...|            Sales|       General - Con|06-04-1948|   GA|            Technician|    Female|       30428|   Asian|    Married|      Fully Meets|                      3|\n",
      "| 3439|Bartholemew|Khemmich|25-May-22|27-Nov-22|  Area Sales Manager|    Charles Parks|bartholemew.khemm...|          EW|        Active|   Full-Time| Zone A|                 Temporary|    Involuntary|  Foot in theory mi...|            Sales|            Splicing|24-11-1981|   CO|               Splicer|      Male|       80820|   Other|     Single|      Fully Meets|                      3|\n",
      "| 3440|       Xana|   Potts|05-Dec-19|17-Feb-23|  Area Sales Manager|   Gregory Walker|xana.potts@bilear...|        CCDR|        Active|    Contract| Zone A|                 Full-Time|    Resignation|  Degree wish scien...|            Sales|Finance & Accounting|06-11-1951|   KY|            Controller|    Female|       40220|   White|   Divorced|      Fully Meets|                      3|\n",
      "| 3441|     Prater|  Jeremy|28-Apr-19|     NULL|  Area Sales Manager|      Tyler Lewis|prater.jeremy@bil...|         BPC|        Active|   Part-Time| Zone A|                 Part-Time|            Unk|                  NULL|            Sales|       General - Con|21-11-1989|   NV|               Lineman|      Male|       89139|   Asian|    Widowed|          Exceeds|                      4|\n",
      "| 3442|     Kaylah|    Moon|09-Jul-19|16-Jun-22|  Area Sales Manager|     Ashley Scott|kaylah.moon@bilea...|         PYZ|        Active|   Full-Time| Zone A|                 Full-Time|     Retirement|  Fear particular m...|            IT/IS|    Field Operations|24-11-1952|   MA|               Laborer|      Male|        2810|   Black|     Single|          Exceeds|                      2|\n",
      "| 3443|    Kristen|    Tate|05-Apr-21|12-May-23|  Area Sales Manager|     Lauren Jones|kristen.tate@bile...|         WBL|        Active|   Full-Time| Zone C|                 Part-Time|      Voluntary|  Wall body wonder ...|            IT/IS|Project Managemen...|08-04-1994|   KY|           Coordinator|      Male|        2621|   Asian|    Widowed|      Fully Meets|                      3|\n",
      "| 3444|      Bobby| Rodgers|28-Nov-21|04-Feb-22|  Area Sales Manager|  Matthew Jackson|bobby.rodgers@bil...|         NEL|        Active|    Contract| Zone A|                 Part-Time|      Voluntary|  Visit foot nearly...|            Sales|           Engineers|15-11-1983|   KY|              Director|      Male|       44553|   Other|    Widowed|      Fully Meets|                      3|\n",
      "| 3445|       Reid|    Park|16-Jan-21|     NULL|  Area Sales Manager|Michelle Mitchell|reid.park@bilearn...|          PL|        Active|    Contract| Zone C|                 Full-Time|            Unk|                  NULL|            Sales|Project Managemen...|07-12-1985|   KY|            Supervisor|    Female|        5360|   Other|    Married|          Exceeds|                      4|\n",
      "| 3446|     Hector|  Dalton|24-Aug-21|     NULL|  Area Sales Manager|    Sydney French|hector.dalton@bil...|         BPC|        Active|   Part-Time| Zone A|                 Part-Time|            Unk|                  NULL|            Sales|    Field Operations|01-05-1996|   TX|               Driller|    Female|       16325|   White|   Divorced|          Exceeds|                      2|\n",
      "+-----+-----------+--------+---------+---------+--------------------+-----------------+--------------------+------------+--------------+------------+-------+--------------------------+---------------+----------------------+-----------------+--------------------+----------+-----+----------------------+----------+------------+--------+-----------+-----------------+-----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employee_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------+-----------+----------+------+-------------+--------------------+--------------------+--------------------+-------------------+-----+--------+--------------------+-----------------+-------------------+--------------+--------------------+------------+\n",
      "|Applicant ID|Application Date| First Name| Last Name|Gender|Date of Birth|        Phone Number|               Email|             Address|               City|State|Zip Code|             Country|  Education Level|Years of Experience|Desired Salary|           Job Title|      Status|\n",
      "+------------+----------------+-----------+----------+------+-------------+--------------------+--------------------+--------------------+-------------------+-----+--------+--------------------+-----------------+-------------------+--------------+--------------------+------------+\n",
      "|        1001|       03-Jun-23|      Scott|  Sheppard|  Male|   31-08-1992|  421-429-7655x39421|perezjanet@exampl...|     597 Smith Point|        Hollandfort|   NV|   57588|          Micronesia|      High School|                  8|      60103.21|Chief Technology ...|Interviewing|\n",
      "|        1002|       15-May-23|    Stanley|     Lewis|  Male|   29-04-1965|+1-451-574-5308x1681|grossmark@example...|    8116 Stuart Loop|  Port Margaretfurt|   TN|   14726|           Greenland|Bachelor's Degree|                 17|      64575.84| Designer, furniture|    Rejected|\n",
      "|        1003|       04-Aug-23|     Javier|        Li|Female|   10-03-1973|       (858)901-5499|katiemaldonado@ex...|5940 Barr Village...|          Dianaland|   TX|    4699|               China|              PhD|                 20|      39422.71|Sound technician,...|    Rejected|\n",
      "|        1004|       28-Jul-23|Christopher|  Johnston| Other|   04-04-2001|  (853)681-1839x2010|sheila73@example.com|     442 Lewis Mount|          Youngfurt|   GA|   34455|               Ghana|      High School|                  8|      51045.11|      Air cabin crew|    Rejected|\n",
      "|        1005|       05-Jun-23|    Melissa|     Hicks| Other|   17-06-1978|  364-575-8478x67812|emilypatterson@ex...|95961 Taylor Circ...| East Ashleyborough|   IN|   21014|     Solomon Islands|  Master's Degree|                  0|      52792.86|       Art therapist|Interviewing|\n",
      "|        1006|       26-Jul-23|  Christian|    Maddox|Female|   14-06-1983|       (894)940-2919|pvelasquez@exampl...|   3030 Bell Islands|          Boonefort|   NC|   34763|             Liberia|  Master's Degree|                 18|      97746.62|Engineer, electro...|   In Review|\n",
      "|        1007|       09-Jun-23|       Paul|   Hammond|Female|   16-08-1963|#################...|aclayton@example.net|   58473 Jenna Trail|         Port Barry|   GA|   57472|               Congo|      High School|                 11|      80119.39|Scientist, resear...|     Offered|\n",
      "|        1008|       15-Jul-23|    Madison|Williamson|  Male|   07-09-1978|001-902-992-9557x692|jeffreyellis@exam...|24740 Gregory Str...|       New Luisfort|   VA|   71682|    Pitcairn Islands|Bachelor's Degree|                  0|      41578.78|Teacher, primary ...|     Offered|\n",
      "|        1009|       16-Jun-23|    Rachael|     Duran|  Male|   11-09-1997|+1-738-583-6354x6...|hamptontimothy@ex...|    375 Flowers Well|        Amandashire|   PW|   25218|               Spain|      High School|                 15|       44489.6|      Phytotherapist|Interviewing|\n",
      "|        1010|       25-May-23|     Sherri|    Taylor|  Male|   24-04-1983|        915.372.0499|   cshaw@example.net|     037 Quinn Route|      Garrisonmouth|   CA|   82074|               Gabon|  Master's Degree|                  4|      97363.53|      Pilot, airline|     Offered|\n",
      "|        1011|       14-May-23|   Jennifer|    Weaver| Other|   22-10-1998|        852.435.8495|sloankrista@examp...|700 Quinn Green S...|        Haileyville|   MS|   37729|         Switzerland|              PhD|                 19|      39252.38|    Theatre director|   In Review|\n",
      "|        1012|       04-Jun-23|       Kyle|     Blake| Other|   25-03-2001|001-527-907-9332x...|shelia63@example.net|611 Thomas Dam Su...|       East Melinda|   OH|   62970|               China|Bachelor's Degree|                  7|      79650.82| Corporate treasurer|     Applied|\n",
      "|        1013|       23-Jul-23|      James|    Bailey|Female|   12-05-1983|       (606)926-6770|fraziermichelle@e...|4469 Holt Divide ...|           Hahnberg|   AZ|   61409|                Guam|  Master's Degree|                 12|      86588.22|Accounting techni...|     Offered|\n",
      "|        1014|       12-Jun-23|      Heidi|      Wood|  Male|   20-11-1965|  (209)368-2818x1932|brentswanson@exam...|   527 Jamie Viaduct|    Christopherberg|   CT|   34112|Central African R...|Bachelor's Degree|                  9|      59082.57|Learning disabili...|    Rejected|\n",
      "|        1015|       04-Jul-23|     Johnny|    Nguyen| Other|   23-11-1971|001-970-594-9559x...|clarkdawn@example...|621 Mitchell Glen...|           Leehaven|   WV|   82030|               Kenya|Bachelor's Degree|                  2|       91301.9|        Web designer|    Rejected|\n",
      "|        1016|       26-Jul-23|     Olivia|    Watson|Female|   09-08-1970|#################...|rachel98@example.com|3578 Warren Prair...|        North Ariel|   NV|   37858|              Belize|  Master's Degree|                  2|       44515.4|Scientist, resear...|Interviewing|\n",
      "|        1017|       16-May-23|      Anita|   Jenkins|  Male|   02-01-2004|        409-660-9413|charles11@example...|      6505 Dawn Burg|          Tonyville|   DE|   54454|             Morocco|  Master's Degree|                 20|      72554.88|Higher education ...|   In Review|\n",
      "|        1018|       12-Jun-23|       John|   Coleman|Female|   01-08-2005|   332.925.0075x0800|smithashley@examp...|5227 William Grov...|   South Andrewport|   HI|   22242|              Poland|Bachelor's Degree|                 20|      52923.21|Merchandiser, retail|     Offered|\n",
      "|        1019|       26-Jun-23|       Adam|      Best| Other|   28-05-2001|       (592)449-4498|   joe34@example.net|599 Mccoy Estate ...|Lake Christianshire|   ME|   84388|             Ukraine|              PhD|                 12|      47680.62|       Buyer, retail|    Rejected|\n",
      "|        1020|       23-May-23|     Cheryl|  Peterson|  Male|   18-09-1990|001-466-805-0058x769| corey49@example.net|   331 James Springs|         Gibbsburgh|   MH|   70864|          Costa Rica|Bachelor's Degree|                  6|      36560.41|Water quality sci...|Interviewing|\n",
      "+------------+----------------+-----------+----------+------+-------------+--------------------+--------------------+--------------------+-------------------+-----+--------+--------------------+-----------------+-------------------+--------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recruitment_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1725256378.6074026\n",
      "1725256378.62379\n",
      "without partition exec_time:  0.016387462615966797\n",
      "1725256378.6384308\n",
      "1725256378.6503756\n",
      "without partition exec_time:  0.011944770812988281\n"
     ]
    }
   ],
   "source": [
    "# state wise partition join and execution time find\n",
    "\n",
    "from time import sleep, time\n",
    "from pyspark.sql.functions import sum,col\n",
    "\n",
    "start_time = time()\n",
    "print(start_time)\n",
    "\n",
    "employee_df.join(recruitment_df, employee_df['FirstName']==recruitment_df['First Name'])\n",
    "\n",
    "end_time = time()\n",
    "\n",
    "print(end_time)\n",
    "print(\"without partition exec_time: \", end_time-start_time)\n",
    "\n",
    "# applying reprtitioning\n",
    "\n",
    "employee_df2 = employee_df.repartition('State')\n",
    "recruitment_df2 = recruitment_df.repartition('state')\n",
    "\n",
    "start_time2 = time()\n",
    "print(start_time2)\n",
    "\n",
    "employee_df2.join(recruitment_df2, employee_df2['FirstName']==recruitment_df2['First Name'])\n",
    "\n",
    "end_time2 = time()\n",
    "print(end_time2)\n",
    "print(\"without partition exec_time: \", end_time2-start_time2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
